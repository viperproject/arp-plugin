## Viper runner configuration file in HOCON format,
## demonstrating available configuration options.
## See
##   https://github.com/typesafehub/config/blob/master/HOCON.md
## for information about the HOCON format.
## See
##   TODO: create corresponding wiki page
## for benchmarking-related tipps and pitfalls.

## Some options take placeholders:
## 	@date@			   Date and time (yyyy-mm-dd-hh-mm-ss) when the benchmark was started.
##	@file_name@		 Name of current input file
##	@path_name@		 Mashup of input file path and name to generate a unique name
##	@rep@			     Current repetition of the same run configuration and file pair
##	@config_name@	 Name of the current run configuration

## Folder that contains the tests. Only .sil files will be considered.
# test_folder = "../silver/src/test/resources/all/basic/"
test_folder = "../arp-plugin/evaluation/performance/test_fast/"

## File listing all tests to use.
# test_files_in_file = "tests-all"

## Tests to be be ignored.
## Note: Paths may be relative but cannot contain wildcards
## Note: Does only work with test_folder, not yet with test_files_in_file
# ignore_files = [
#   "domains.sil",
#   "sequences/nil.sil"
# ]

## Print files included in benchmark before benchmark starts
list_files = true

## Disable accessibility checking of files
# check_files_accessible = false

## Disable user confirmation before benchmark starts
# confirm_start = false

## Collect the output of programs executed during a benchmark
print_output = true

## The stdout output is written to 'stdout_file' if the option is set, to stdout
## otherwise. Analogous for stderr.
## The output files may contain the following placeholders: @date@.
# stdout_file = "results/@date@/output_stdout.txt"
# stderr_file = "results/@date@/output_stderr.txt"

## Number of repetitions for a single test file with the same run configuration.
repetitions = 20

## Timeout in seconds for a single run for one input file.
## 0 or smaller values set the timeout to infinity.
timeout = 120

## Where to save the results of the benchmark.
## Property'results.path' is mandatory and may contain the following
## placeholders: @date@.
results = {
  path = "results/@date@",
  individual_timings = "timings.csv",
  per_config_timings = "per_config_timings.csv",
  avg_per_config_timings = "avg_per_config_timings.csv"
}

## Declare run configurations, i.e. programs to benchmark.
## Each run configuration must have a 'name' and a 'command' property.
##
## The 'command' denotes the program to benchmark; when executed, the current test
## file is passed as the only argument.
## The 'command' property may contain any of the placeholders described above.
##
## Placeholders in other configuration commands, such as 'pre_round_commands', are
## not yet supported.

# run_configurations = [
#   {
#     name = "configA",
#     command = ["ls", "-l"]
#     pre_round_commands = [
#       ["echo", "Start 01 configA"],
#       ["echo", "Start 02 configA"]
#     ],
#     post_round_commands = [["echo", "Stop configA"]]
#   },
#   {
#     name = "configB",
#     command = ["ls", "-a"]
#     pre_round_commands = [
#       ["echo", "Start configB"],
#     ],
#     post_round_commands = [
#       ["echo", "Stop 01 configB"],
#       ["echo", "Stop 02 configB"]
#     ]
#   }
# ]

cmd_silicon = [
 "/home/developer/source/viper-runner/scripts/silicon.sh",
 "--mode", "nailgun",
 "--",
 "--numberOfParallelVerifiers", "1",
 "--plugin", "PerformanceParser"
]

cmd_silicon_timeout = [
  "/home/developer/source/viper-runner/scripts/silicon.sh",
  "--mode", "nailgun",
  "--",
  "--numberOfParallelVerifiers", "1",
  "--checkTimeout", "50",
  "--plugin", "PerformanceParser"
]

cmd_carbon = [
  "/home/developer/source/viper-runner/scripts/carbon.sh",
  "--mode", "nailgun",
  "--",
  "--plugin", "PerformanceParser"
]

cmd_restart_nailgun = [
 "/home/developer/source/viper-runner/scripts/ng-server.sh",
 "--restart"
]

cmd_kill_z3_instances = ["pkill", "-e", "-9", "z3"]

cmd_warmup_silicon = ["/home/developer/source/viper-runner/scripts/warmup-silicon.sh"]
cmd_warmup_carbon = ["/home/developer/source/viper-runner/scripts/warmup-carbon.sh"]

run_configurations = [
 ##
 ## Test with and withoud the plugin
 ## TODO: test with different optimizations in ARPPlugin
 ##
 {
   name = "silicon",
   command = ${cmd_silicon} [${test_folder}"@file_name@"],
   pre_round_commands = [
     ${cmd_restart_nailgun} ["fatjars/silicon-base.jar"],
     ${cmd_warmup_silicon}
   ],
   post_round_commands = [${cmd_kill_z3_instances}]
 }, {
    name = "silicon_timeout",
    command = ${cmd_silicon_timeout} [${test_folder}"@file_name@"],
    pre_round_commands = [
      ${cmd_restart_nailgun} ["fatjars/silicon-base.jar"],
      ${cmd_warmup_silicon}
    ],
    post_round_commands = [${cmd_kill_z3_instances}]
  }, {
    name = "carbon",
    command = ${cmd_carbon} [${test_folder}"@file_name@"],
    pre_round_commands = [
      ${cmd_restart_nailgun} ["fatjars/carbon-base.jar"],
      ${cmd_warmup_carbon}
    ],
    post_round_commands = [${cmd_kill_z3_instances}]
  }
]
